\chapter{Conclusion \& Perspectives}
\label{ch:Conclusion & Perspectives}

In this work an approach for identification of trajectory anomalies in uncertain ST data was proposed and discussed. To implement the approach and further perform an evaluation, the framework was developed. The source code of the implemented framework is available on GitHub repository \cite{online:mt_anomalies}. For solving the task of outliers detection the clustering approach was used as a basis, specifically agglomerative hierarchical clustering algorithm. To calculate the similarity and dissimilarity between trajectories and clusters, the LCSS distance was chosen. However, as it was mentioned in previous chapters, LCSS distance calculation becomes infeasible for long trajectories. For that reason the approximation of input trajectories was performed using polynomial regression and Douglas-Peucker N algorithms. According to the evaluation results, for the case of polynomial regression the best accuracy of approximation is achieved while using the 3\up{th} and 4\up{th}-degree polynomial functions jointly. In case of using a Douglas-Peucker N algorithm, setting a desired trajectory length to 8 trajectory points led to best relation between the complexity of inter-trajectory distance calculation and the necessity to keep the initial trajectory form. 

Thereby, clustering was performed on a filtered set of approximated input trajectories using key points for each of them. The accuracy of the performed clustering was evaluated using a DI index and is equal to $0.95$ value, which can be considered as an acceptable result and denotes a qualitative division into clear distinguishable clusters. Hereafter for each output cluster representative trajectory was chosen as its model to simplify the further classification of a new input trajectory.

As a result of this work following conclusions and deductions can be drawn:

\begin{itemize}
	\setlength\itemsep{0em}	
	\item approximation of short trajectories with a non-constant speed requires higher-order polynomial functions for approximation;
	\item notwithstanding that LCSS distance allows trajectories to be of different lengths, it becomes extremely computationally expensive and complex for trajectories with more that 11-12 trajectory points;
	\item approximation using a polynomial regression works well with the trajectory data, since it is known in advance that spatial coordinates of a trajectory are functionally dependent on the time (according to principles of physics, speed, acceleration, etc.);
	\item approximation using a Douglas-Peucker N algorithm works faster and more accurate in terms of keeping the spatial information and representing main curves of the initial trajectory according to calculated positional errors, but Polynomial Regression is preferable for the cases, when temporal information is needed to be preserved and analyzed;
	\item using the adaptive parameter values significantly increases the accuracy of results according to both visual and quantitative (DI index) tests.
\end{itemize}

\bigbreak

\subsubsection{Further perspectives}

The implemented algorithm is designed in an offline-learning manner, that means that models of normal trajectories are learned offline beforehand and are not updated with new upcoming data on an on-going basis. The future researches can include investigating an opportunity of updating normal trajectories database in order to make the framework more adaptable to actual traffic data.

Moreover, it can be seen that DBSCAN works well in general with the source data, however, clusters contain critical roughness and inaccuracy in comparison with clusters obtained by Agglomerative Hierarchical algorithm, especially for trajectories located either too close to the \textit{CP} or too far from it. DBSCAN can be modified to process adaptive $\varepsilon$ values for more adequate clusters, which are comparable with the adaptive Agglomerative Hierarchical clustering results.
